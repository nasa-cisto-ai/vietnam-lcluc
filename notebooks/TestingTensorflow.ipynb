{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c5a20cb-0196-441e-a527-a605da2ba496",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-08 07:32:50.908082: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import rioxarray as rxr\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from osgeo import gdal_array\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "578ccf74-3807-4059-b89a-49c9bd819c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-08 07:33:07.721697: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-03-08 07:33:07.721903: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-03-08 07:33:07.772145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:62:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2022-03-08 07:33:07.772192: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-03-08 07:33:07.772231: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2022-03-08 07:33:07.772257: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-03-08 07:33:07.772292: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-03-08 07:33:07.772320: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-03-08 07:33:07.772340: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-03-08 07:33:07.772361: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-03-08 07:33:07.772387: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-03-08 07:33:07.774587: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-03-08 07:33:07.775118: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-08 07:33:07.778859: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-03-08 07:33:07.780074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:62:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2022-03-08 07:33:07.780117: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-03-08 07:33:07.780133: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2022-03-08 07:33:07.780147: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-03-08 07:33:07.780166: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-03-08 07:33:07.780180: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-03-08 07:33:07.780193: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-03-08 07:33:07.780216: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-03-08 07:33:07.780229: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-03-08 07:33:07.782317: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-03-08 07:33:07.782374: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-03-08 07:33:12.176045: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-03-08 07:33:12.176083: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-03-08 07:33:12.176093: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-03-08 07:33:12.179781: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30059 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:62:00.0, compute capability: 7.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 4) (256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('/adapt/nobackup/projects/ilab/projects/Vietnam/Jordan/VIETNAM_PRIORITY/clouds-binary-mixed-std/58-0.04.hdf5')\n",
    "net_input_shape = model.input_shape[1:]\n",
    "net_output_shape = model.output_shape[1:]\n",
    "net_output_shape = (256, 256, 1)\n",
    "print(net_input_shape, net_output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1045af98-94e3-4ed2-9b4c-fc0626f89795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 69.5 ms, sys: 10.4 ms, total: 79.9 ms\n",
      "Wall time: 146 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "image_filename = '/att/gpfsfs/briskfs01/ppl/mwooten3/Vietnam_LCLUC/TOA/M1BS/pansharpen_TamNongClip/WV02_20130125_M1BS_103001001DD53500-toa_pansharpen_clip.tif'\n",
    "# image_filename = '/adapt/nobackup/projects/ilab/projects/Vietnam/Jordan/VIETNAM_PRIORITY/tree_model_data/data/Keelin02_20130125_data.tif'\n",
    "image = rxr.open_rasterio(image_filename, cache=True)\n",
    "image = image.transpose(\"y\", \"x\", \"band\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fb56368-f1c0-4632-93b4-b84f569dfde3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38702, 71223, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30cb981-82b2-4987-b549-9492adef6770",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "image = tf.convert_to_tensor(image)\n",
    "image = tf.expand_dims(image, 0)\n",
    "print(image.shape, image.device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcaf73c-7522-442d-a680-0648e555e8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "image[0, 512:1024, 512:1024, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f3994a-b390-48f6-87cd-1a088a65dfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#tf.image.extract_patches(\n",
    "#    images, sizes, strides, rates, padding, name=None\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2eece5-6fc7-4f09-95a8-2e5b96f4d62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = tf.image.extract_patches(image, [1, net_input_shape[0], net_input_shape[1], 1],\n",
    "                                  [1, net_output_shape[0], net_output_shape[1], 1],\n",
    "                                  [1, 1, 1, 1], padding='VALID')\n",
    "print(chunks.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fba84b1-d4ff-410d-bec4-9b870972461c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    chunks = tf.reshape(chunks, (-1,) + net_input_shape)\n",
    "chunks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce9a753-cb64-4e45-ae94-ca8e4d6d6bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in range(0, chunks.shape[0], 4):\n",
    "    #print(chunks[i:i+4].shape)\n",
    "    model.predict_on_batch(chunks[i:i+4])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f206af2-6823-404b-89fc-3dfb909bb60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def _predict_array(self, data: np.ndarray, image_nodata_value):\n",
    "        \n",
    "        Runs model on data.\n",
    "        Parameters\n",
    "        ----------\n",
    "        data: np.ndarray\n",
    "            Block of image to apply the model to.\n",
    "        image_nodata_value: dtype of data\n",
    "            Nodata value in image. If given, nodata values are\n",
    "            replaced with nans in output.\n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray:\n",
    "            Result of applying model to data.\n",
    "        \n",
    "        net_input_shape = self._model.input_shape[1:]\n",
    "        net_output_shape = self._model.output_shape[1:]\n",
    "\n",
    "        image = tf.convert_to_tensor(data)\n",
    "        image = tf.expand_dims(image, 0)\n",
    "\n",
    "        assert net_input_shape[2] == data.shape[2],\\\n",
    "               'Model expects %d input channels, data has %d channels' % (net_input_shape[2], data.shape[2])\n",
    "\n",
    "        # supports variable input size, just toss everything in\n",
    "        if net_input_shape[0] is None and net_input_shape[1] is None:\n",
    "            result = np.squeeze(self._model.predict_on_batch(image))\n",
    "            if not result.flags['WRITEABLE']: # older tensorflow version\n",
    "                result = np.array(result)\n",
    "            if image_nodata_value is not None:\n",
    "                x0 = (data.shape[1] - result.shape[1]) // 2\n",
    "                y0 = (data.shape[0] - result.shape[0]) // 2\n",
    "                invalid = (data if len(data.shape) == 2 else \\\n",
    "                          data[:, :, 0])[y0:y0 + result.shape[0], x0:x0 + result.shape[1]] == image_nodata_value\n",
    "                if len(result.shape) == 2:\n",
    "                    result[invalid] = math.nan\n",
    "                else:\n",
    "                    result[invalid, :] = math.nan\n",
    "            return result\n",
    "\n",
    "        out_shape = (data.shape[0] - net_input_shape[0] + net_output_shape[0],\n",
    "                     data.shape[1] - net_input_shape[1] + net_output_shape[1])\n",
    "\n",
    "        out_type = tf.dtypes.as_dtype(self._model.dtype)\n",
    "        chunks = tf.image.extract_patches(image, [1, net_input_shape[0], net_input_shape[1], 1],\n",
    "                                          [1, net_output_shape[0], net_output_shape[1], 1],\n",
    "                                          [1, 1, 1, 1], padding='VALID')\n",
    "        chunks = tf.reshape(chunks, (-1,) + net_input_shape)\n",
    "\n",
    "        best = np.zeros((chunks.shape[0],) + net_output_shape, dtype=out_type.as_numpy_dtype)\n",
    "        # do 8 MB at a time... this is arbitrary, may want to change in future\n",
    "        BATCH_SIZE = max(1, int(8 * 1024 * 1024 / net_input_shape[0] / net_input_shape[1] /\n",
    "                                net_input_shape[2] / out_type.size))\n",
    "        for i in range(0, chunks.shape[0], BATCH_SIZE):\n",
    "            best[i:i+BATCH_SIZE] = self._model.predict_on_batch(chunks[i:i+BATCH_SIZE])\n",
    "\n",
    "        retval = np.zeros(out_shape + (net_output_shape[-1],))\n",
    "        for chunk_idx in range(0, best.shape[0]):\n",
    "            r = (chunk_idx // (  out_shape[1] // net_output_shape[1])) * net_output_shape[0]\n",
    "            c = (chunk_idx  % ( out_shape[1] // net_output_shape[1])) * net_output_shape[1]\n",
    "            retval[r:r+net_output_shape[0],c:c+net_output_shape[1],:] = best[chunk_idx,:,:,:]\n",
    "\n",
    "        if image_nodata_value is not None:\n",
    "            ox = (data.shape[1] - out_shape[1]) // 2\n",
    "            oy = (data.shape[0] - out_shape[0]) // 2\n",
    "            output_slice = data[oy:-oy, ox:-ox, 0]\n",
    "            retval[output_slice == image_nodata_value] = math.nan\n",
    "\n",
    "        return retval\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab10cac-208a-414d-bce6-9acd6e3e9909",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ilab-kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
